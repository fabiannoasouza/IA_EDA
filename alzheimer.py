# -*- coding: utf-8 -*-
"""Alzheimer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NJvqnhxbSqUSf7W6vHjjZk7ydJgBy_Ak
"""

import pandas as pd

path = '/content/alzheimers_disease_data.csv'

df = pd.read_csv(path)

print("DataFrame carregado com sucesso!")
display(df.head())

# Seleciona as colunas numéricas
numeric_cols = df.select_dtypes(include=['float64', 'int64'])

print("--- Verificação de Outliers em Colunas Contínuas ---")
found_outliers = False

# Itera sobre cada coluna numérica
for column in numeric_cols.columns:
    # A NOVA REGRA: só analisa se a coluna tiver mais de 5 valores únicos
    if df[column].nunique() > 5:
        Q1 = df[column].quantile(0.25)
        Q3 = df[column].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 1.5 * IQR
        upper_bound = Q3 + 1.5 * IQR

        outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]

        if not outliers.empty:
            print(f"Coluna '{column}' possui {len(outliers)} outlier(s).")
            found_outliers = True

# Se nenhum outlier for encontrado após a filtragem, informa o usuário
if not found_outliers:
    print("Nenhum outlier encontrado nas colunas numéricas contínuas.")

"""Se algum número aqui for menor que o total de entradas (que será mostrado na primeira linha), significa que temos dados faltando naquela coluna.

75% max - entao sem indicios de outliers
"""

# Mostra um resumo técnico do dataframe
print("--- Informações Gerais (Tipos e Nulos) ---")
df.info()

print("\n\n--- Resumo Estatístico das Colunas Numéricas ---")
display(df.describe())

"""Abaixo: Nenhum dado nulo
Coluna DoctorInCharge: A mensagem ['XXXConfid'] significa que a única informação presente em todas as linhas dessa coluna é o texto "XXXConfid". Com isso ela será eliminada!
"""

# Verifica se há algum valor nulo em qualquer coluna do dataframe
print("--- Verificação de Dados Faltando ---")
print(df.isnull().sum())

# Identifica o nome da coluna de texto e mostra seus valores únicos
coluna_texto = df.select_dtypes(include=['object']).columns[0]
print(f"\n\n--- Análise da Coluna de Texto: '{coluna_texto}' ---")
print("Valores únicos nesta coluna:")
print(df[coluna_texto].unique())

# Remove a coluna 'DoctorInCharge' do dataframe 'df'
df = df.drop(columns=['DoctorInCharge'])

# Confirma que a coluna foi removida, mostrando as 5 primeiras linhas novamente
print("Coluna 'DoctorInCharge' removida com sucesso!")
display(df.head())

"""**EDA**

Proporção entre as classes. Gráfico básico de contagem


"""

import matplotlib.pyplot as plt
import seaborn as sns


sns.set_style("whitegrid")
plt.figure(figsize=(8, 6))
sns.countplot(x='Diagnosis', data=df)


plt.title('Gráfico 1: Distribuição dos Diagnósticos', fontsize=16)
plt.xlabel('Diagnóstico (0 = Não Alzheimer, 1 = Alzheimer)', fontsize=12)
plt.ylabel('Quantidade de Pacientes', fontsize=12)

plt.show()

"""# Gráfico de densidade para investigar a idade
Obs.:


*   As idades se sobrepõem bastante
*   O grupo sem Alzheimer tem um pico mais forte e concentrado em uma idade mais jovem (por volta dos 65-75 anos).
*   O grupo com Alzheimer, como você disse, é mais "distribuído"





"""

plt.figure(figsize=(10, 6))
sns.kdeplot(data=df, x='Age', hue='Diagnosis', fill=True, common_norm=False)


plt.title('Gráfico 2: Distribuição de Idade por Diagnóstico', fontsize=16)
plt.xlabel('Idade', fontsize=12)
plt.ylabel('Densidade', fontsize=12)
plt.legend(title='Diagnóstico', labels=['Alzheimer', 'Não Alzheimer']) # Ajusta a legenda


plt.show()

"""Uma pontuação baixa no teste MMSE está fortemente associada ao diagnóstico de Alzheimer neste dataset."""

plt.figure(figsize=(8, 7))
sns.boxplot(x='Diagnosis', y='MMSE', data=df)


plt.title('Gráfico 3: Box Plot do Score MMSE por Diagnóstico', fontsize=16)
plt.xlabel('Diagnóstico (0 = Não Alzheimer, 1 = Alzheimer)', fontsize=12)
plt.ylabel('Pontuação no Teste MMSE', fontsize=12)


plt.show()

"""A "nuvem" de pontos do diagnóstico 1 (Alzheimer) se concentra na parte de baixo do gráfico (indicando MMSE baixo), especialmente conforme a idade (Age) avança para a direita. A nuvem do diagnóstico 0 fica claramente na parte de cima (indicando MMSE alto)."""

plt.figure(figsize=(10, 7))
sns.scatterplot(data=df, x='Age', y='MMSE', hue='Diagnosis', alpha=0.7)

plt.title('Gráfico 4: Relação entre Idade, MMSE e Diagnóstico', fontsize=16)
plt.xlabel('Idade', fontsize=12)
plt.ylabel('Pontuação no Teste MMSE', fontsize=12)

plt.show()

"""Diagonal Principal: A linha diagonal de cor vermelho-escura que cruza o gráfico, mostra que cada variável tem uma correlação perfeita consigo mesma."""

plt.figure(figsize=(20, 15))
corr_matrix = df.corr()

# Usando a função heatmap do seaborn para desenhar o mapa de calor
sns.heatmap(corr_matrix, cmap='coolwarm')
plt.title('Gráfico 5: Mapa de Calor de Correlação das Variáveis', fontsize=18)
plt.show()

"""Detectando Outliers: Não possui!"""

plt.figure(figsize=(18, 6))
plt.subplot(1, 3, 1) # (1 linha, 3 colunas, 1º gráfico)
sns.boxplot(y=df['BMI'])
plt.title('Box Plot para BMI', fontsize=14)
plt.ylabel('BMI', fontsize=12)


plt.subplot(1, 3, 2) # (1 linha, 3 colunas, 2º gráfico)
sns.boxplot(y=df['CholesterolTotal'])
plt.title('Box Plot para Colesterol Total', fontsize=14)
plt.ylabel('Colesterol Total', fontsize=12)


plt.subplot(1, 3, 3) # (1 linha, 3 colunas, 3º gráfico)
sns.boxplot(y=df['SystolicBP'])
plt.title('Box Plot para Pressão Arterial', fontsize=14)
plt.ylabel('Pressão Sistólica', fontsize=12)


plt.tight_layout()
plt.show()

"""# Aplicando Machine Learning"""

y = df['Diagnosis']


X = df.drop(columns=['Diagnosis', 'PatientID'])


print("Dimensões de X (características):", X.shape)
print("Dimensões de y (alvo):", y.shape)

print("\nPrimeiras linhas de X:")
display(X.head())

#treinando

from sklearn.model_selection import train_test_split

# Divide os dados: 80% para treino, 20% para teste
# random_state=42 garante que a divisão seja sempre a mesma se rodarmos o código de novo
# stratify=y é o comando para fazer a divisão estratificada
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Vamos verificar se a estratificação funcionou
print("--- Verificação da Proporção de Diagnósticos ---")
print(f"Proporção no dataset original: {y.value_counts(normalize=True)[1]:.2f}")
print(f"Proporção no conjunto de treino: {y_train.value_counts(normalize=True)[1]:.2f}")
print(f"Proporção no conjunto de teste: {y_test.value_counts(normalize=True)[1]:.2f}")

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score
import seaborn as sns
import matplotlib.pyplot as plt
import pandas as pd

from sklearn.naive_bayes import GaussianNB


model_nb = GaussianNB()
model_nb.fit(X_train, y_train)


y_pred_nb = model_nb.predict(X_test)


print("--- Resultados do Modelo Naive Bayes ---")

# Acurácia
accuracy = accuracy_score(y_test, y_pred_nb)
print(f"Acurácia: {accuracy:.4f}")

# Relatório de Classificação (com precision, recall, f1-score)
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred_nb))

# Matriz de Confusão
print("\nMatriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_nb)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsto')
plt.ylabel('Verdadeiro')
plt.show()

from sklearn.linear_model import LogisticRegression


# Inicializa o modelo
# max_iter=1000 ajuda o modelo a ter mais "tentativas" para encontrar a melhor solução
model_lr = LogisticRegression(max_iter=1000)

# Treina o modelo com os dados de treino
model_lr.fit(X_train, y_train)


y_pred_lr = model_lr.predict(X_test)
print("--- Resultados do Modelo Regressão Logística ---")

# Acurácia
accuracy = accuracy_score(y_test, y_pred_lr)
print(f"Acurácia: {accuracy:.4f}")

# Relatório de Classificação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred_lr))

# Matriz de Confusão
print("\nMatriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_lr)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsto')
plt.ylabel('Verdadeiro')
plt.show()

from sklearn.tree import DecisionTreeClassifier


# random_state=42 garante que a árvore seja construída da mesma forma sempre
model_dt = DecisionTreeClassifier(random_state=42)


model_dt.fit(X_train, y_train)
y_pred_dt = model_dt.predict(X_test)

print("--- Resultados do Modelo Árvore de Decisão ---")

# Acurácia
accuracy = accuracy_score(y_test, y_pred_dt)
print(f"Acurácia: {accuracy:.4f}")

# Relatório de Classificação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred_dt))

# Matriz de Confusão
print("\nMatriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_dt)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsto')
plt.ylabel('Verdadeiro')
plt.show()

from sklearn.ensemble import RandomForestClassifier


# n_estimators=100 significa que vamos criar 100 árvores na nossa floresta
# random_state=42 para reprodutibilidade
model_rf = RandomForestClassifier(n_estimators=100, random_state=42)


model_rf.fit(X_train, y_train)
y_pred_rf = model_rf.predict(X_test)


print("--- Resultados do Modelo Random Forest ---")

# Acurácia
accuracy = accuracy_score(y_test, y_pred_rf)
print(f"Acurácia: {accuracy:.4f}")

# Relatório de Classificação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred_rf))

# Matriz de Confusão
print("\nMatriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_rf)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsto')
plt.ylabel('Verdadeiro')
plt.show()

from sklearn.ensemble import GradientBoostingClassifier


# n_estimators=100 significa que vamos criar 100 árvores em sequência
# random_state=42 para reprodutibilidade
model_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)


model_gb.fit(X_train, y_train)
y_pred_gb = model_gb.predict(X_test)


print("--- Resultados do Modelo Gradient Boosting ---")

# Acurácia
accuracy = accuracy_score(y_test, y_pred_gb)
print(f"Acurácia: {accuracy:.4f}")

# Relatório de Classificação
print("\nRelatório de Classificação:")
print(classification_report(y_test, y_pred_gb))

# Matriz de Confusão
print("\nMatriz de Confusão:")
cm = confusion_matrix(y_test, y_pred_gb)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsto')
plt.ylabel('Verdadeiro')
plt.show()

# Dicionário para armazenar as previsões
predictions = {
    "Naive Bayes": y_pred_nb,
    "Regressão Logística": y_pred_lr,
    "Árvore de Decisão": y_pred_dt,
    "Random Forest": y_pred_rf,
    "Gradient Boosting": y_pred_gb
}


results = []


for name, y_pred in predictions.items():
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, pos_label=1)
    recall = recall_score(y_test, y_pred, pos_label=1)
    f1 = f1_score(y_test, y_pred, pos_label=1)
    results.append([name, accuracy, precision, recall, f1])


results_df = pd.DataFrame(results, columns=["Modelo", "Acurácia", "Precisão", "Recall", "F1-Score"])

print("--- Tabela Comparativa de Métricas ---")
display(results_df.sort_values(by="F1-Score", ascending=False))


plt.figure(figsize=(12, 8))
df_melted = results_df.melt(id_vars="Modelo", var_name="Métrica", value_name="Pontuação")


sns.barplot(x="Modelo", y="Pontuação", hue="Métrica", data=df_melted)

plt.title('Comparação Final de Desempenho dos Modelos', fontsize=16)
plt.ylabel('Pontuação (0.0 a 1.0)', fontsize=12)
plt.xlabel('')
plt.xticks(rotation=45, ha='right')
plt.ylim(0, 1.05)
plt.legend(title='Métrica', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

"""k-fold onde k=5"""

from sklearn.model_selection import cross_val_score
from sklearn.ensemble import GradientBoostingClassifier
import numpy as np

# 1. Inicializa o modelo (pode ser qualquer um, vamos usar nosso campeão)
model_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)

# 2. Executa a validação cruzada
# Usamos o dataset completo (X e y), pois a função faz a divisão internamente
# cv=5 significa que estamos usando 5 folds (k=5)
# 'scoring' define qual métrica queremos, 'accuracy' é a acurácia
scores = cross_val_score(model_gb, X, y, cv=5, scoring='accuracy')

# 3. Mostra os resultados
print("--- Resultados da Validação Cruzada (K-Fold) ---")
print(f"Acurácia em cada uma das 5 rodadas: {scores}")
print(f"\nMédia da Acurácia: {np.mean(scores):.4f}")
print(f"Desvio Padrão da Acurácia: {np.std(scores):.4f}")

from sklearn.model_selection import cross_val_predict
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# 1. Inicializa o modelo
model_gb = GradientBoostingClassifier(n_estimators=100, random_state=42)

# 2. Obtém as previsões usando a validação cruzada
y_pred_cv = cross_val_predict(model_gb, X, y, cv=5)

# 3. Agora podemos criar a matriz de confusão
print("--- Matriz de Confusão da Validação Cruzada (K-Fold) ---")
cm_cv = confusion_matrix(y, y_pred_cv)
sns.heatmap(cm_cv, annot=True, fmt='d', cmap='Blues')
plt.xlabel('Previsto')
plt.ylabel('Verdadeiro')
plt.show()